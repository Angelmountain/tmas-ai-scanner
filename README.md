# TMAS AI Scanner Pipeline

Automated LLM endpoint security testing using **Trend Micro Artifact Scanner (TMAS) AI Scanner** via GitHub Actions.

Tests any OpenAI-compatible LLM endpoint for vulnerabilities including prompt injection, jailbreaking, system prompt leakage, data exfiltration, and more â€” using OWASP LLM Top 10 and MITRE ATT&CK frameworks.

## Quick Start

### 1. GitHub Actions (Recommended)

Go to **Actions** > **AI Security Scan** > **Run workflow** and fill in:

| Input | Description | Example |
|-------|-------------|---------|
| **Vision One API Key** | Your Trend Micro Vision One API key | `eyJ0eXAi...` |
| **Vision One Region** | Region of your Vision One instance | `eu-central-1` |
| **LLM Endpoint** | Chat completions URL of the LLM to test | `https://api.openai.com/v1` |
| **LLM API Key** | API key for the LLM endpoint | `sk-...` |
| **Model** | Model name to target | `gpt-4` |
| **Attack Preset** | `owasp` or `mitre` | `owasp` |
| **System Prompt** | *(Optional)* System prompt to test against | `You are a helpful assistant...` |

### 2. Local Usage

```bash
# Install dependencies
pip install -r requirements.txt

# Download TMAS CLI
TMAS_VER=$(curl -sf https://ast-cli.xdr.trendmicro.com/tmas-cli/metadata.json | python3 -c "import json,sys; print(json.load(sys.stdin)['latestVersion'].lstrip('v'))")
curl -sf "https://ast-cli.xdr.trendmicro.com/tmas-cli/${TMAS_VER}/tmas-cli_Linux_x86_64.tar.gz" | tar xz tmas
chmod +x tmas

# Generate config
python scripts/generate_config.py \
  --endpoint "https://api.openai.com/v1" \
  --llm-api-key "$OPENAI_API_KEY" \
  --model "gpt-4" \
  --preset "owasp"

# Run scan
export TMAS_API_KEY="your-vision-one-api-key"
python scripts/run_scan.py \
  --config config.yaml \
  --region eu-central-1 \
  --output-dir results \
  --verbose
```

## Supported LLM Endpoints

Any endpoint that accepts the OpenAI chat completion format works:

| Provider | Endpoint URL | Notes |
|----------|-------------|-------|
| **OpenAI** | `https://api.openai.com/v1` | GPT-4, GPT-4o, GPT-3.5-turbo |
| **Azure OpenAI** | `https://<resource>.openai.azure.com/openai/deployments/<deployment>/chat/completions?api-version=2024-02-01` | Your Azure deployment |
| **Ollama** | `http://localhost:11434/v1` | Local models (llama3, mistral, etc.) |
| **vLLM** | `http://localhost:8000/v1/chat/completions` | Self-hosted models |
| **LiteLLM** | `http://localhost:4000/v1/chat/completions` | Proxy for any model |
| **Custom** | Any URL | Must accept OpenAI chat format |

## Attack Presets

### `owasp` (Default)
Tests against the [OWASP Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/):
- Prompt Injection (LLM01)
- Insecure Output Handling (LLM02)
- Training Data Poisoning (LLM03)
- Model Denial of Service (LLM04)
- Supply Chain Vulnerabilities (LLM05)
- Sensitive Information Disclosure (LLM06)
- Insecure Plugin Design (LLM07)
- Excessive Agency (LLM08)
- Overreliance (LLM09)
- Model Theft (LLM10)

### `mitre`
Tests against MITRE ATT&CK framework mappings for AI/ML systems.

## Configuration File Format

The `tmas aiscan llm` command requires a YAML config:

```yaml
version: "1.0"
target:
  endpoint: "https://api.openai.com/v1"
  api_key: "sk-your-openai-key"
  model: "gpt-4"
  system_prompt: "You are a helpful assistant"  # optional
attack_preset: "owasp"  # or "mitre"
```

This file is auto-generated by `scripts/generate_config.py`.

## Output

### JSON (`results/latest.json`)
Machine-readable results containing:
- Exit code and timestamps
- Parsed scan findings
- Raw TMAS output
- Per-objective pass/fail status

### HTML (`results/latest.html`)
Styled report with:
- Risk level badge (CRITICAL / HIGH / MEDIUM / LOW)
- Summary statistics (total findings, pass/fail counts)
- Scan configuration details
- Detailed findings table
- Full raw output

## Architecture

```
.github/workflows/ai-security-scan.yml    # GitHub Actions pipeline
scripts/
  generate_config.py                       # Config YAML generator
  run_scan.py                              # Scan runner + report generator
results/                                   # Output directory (gitignored)
  latest.json                              # Latest scan results
  latest.html                              # Latest HTML report
  scan_results_YYYYMMDD_HHMMSS.json        # Timestamped results
  scan_report_YYYYMMDD_HHMMSS.html         # Timestamped report
```

## Requirements

- **Trend Micro Vision One** account with API key
- **LLM endpoint** with API key (OpenAI, Azure, self-hosted, etc.)
- Python 3.10+ (for local runs)
- TMAS CLI binary (auto-downloaded in pipeline)

## Vision One Regions

| Region | ID |
|--------|-----|
| US | `us-east-1` |
| Europe | `eu-central-1` |
| Australia | `ap-southeast-2` |
| India | `ap-south-1` |
| Japan | `ap-northeast-1` |
| Singapore | `ap-southeast-1` |
| Middle East | `me-central-1` |

## Security Notes

- API keys are passed as workflow inputs and never stored in the repo
- The generated `config.yaml` is gitignored
- All results in `results/` are gitignored
- Pipeline logs redact API keys from config output
- Use GitHub repository secrets for recurring automated scans

## License

MIT
